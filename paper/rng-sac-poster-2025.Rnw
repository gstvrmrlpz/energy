\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{algorithm}
\usepackage{algorithmic}

\setcopyright{acmcopyright}

\acmDOI{xx.xxx/xxx_x}

\acmISBN{979-8-4007-0629-5/25/03}

%Conference
\acmConference[SAC'25]{ACM SAC Conference}{March 31 â€“April 4, 2025}{Sicily, Italy}
\acmYear{2025}
\copyrightyear{2025}


\acmArticle{4}
\acmPrice{15.00}

\begin{document}
\title{Minimizing the energy consumption of (pseudo) random number generators}
\subtitle{}

\renewcommand{\shorttitle}{Minimizing the energy consumption of (pseudo) random number generators}

\author{Ben Trovato}
\authornote{Boilerplate author names have been kept for double-blind review.}
\orcid{1234-5678-9012}
\affiliation{%
  \institution{Institute for Clarity in Documentation}
  \streetaddress{P.O. Box 1212}
  \city{Dublin}
  \state{Ohio}
  \country{USA}
  \postcode{43017-6221}
}
\email{trovato@corporation.com}

\renewcommand{\shortauthors}{B. Trovato}


\begin{abstract}
Pseudo random number generators are an essential part of every machine learning or metaheuristic algorithm. Even if every call will not, by itself, consume a large amount of energy, they are invoked so many times in any algorithm implementation that their consumption will add up to a significant amount, impacting overall consumption in several percentage points. In this poster we will examine what is the energy consumption, as well as the number of random number generated per joule, that can be achieved by different random number generators implemented in low-level languages. Our conclusion is that there can be a factor of two difference between the one that consumes the largest and the least amount of energy.
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}


\keywords{Green computing, software engineering, evolutionary algorithms, genetic algorithms, energy-aware algorithms, random number generators}


\maketitle

\section{Introduction}

Random number generators (RNGs) \cite{marsaglia2003random} are a class of algorithms that generate an unpredictable series of numbers with specific properties, or later converted to specific classes of values (like Boolean values or characters). They need a {\em seed} (which can be a single number or a vector of them) as input, and they will produce the {\em next} element in the cycle applying a series of operations to the seed and subsequent numbers generated from it. Those are generally {\em integer} operations; this is why, in general, RNGs are called {\em pseudo} RNGs: once the seed is known, the rest of the operations are deterministic. The complexity (and, inherently, the energy consumption) of these operations can go over a great range depending on the properties required from the RNG; so-called {\em cryptographycally secure} RNGs have the strictest requirements, and thus the lowest performance and highest energy consumption.

RNGs, however, are not used exclusively in cryptographic operations: any stochastic algorithm will need them, and will call them repeatedly in any kind of operations. Evolutionary algorithms, for instance, will need several calls to generate a point of mutation or crossover, as well as to generate randomly the initial population or any newly generated individual that is needed.

<<sac.rnd.intro, echo=FALSE, message=FALSE, fig.env="figure*",fig.cap="Boxplot of energy consumption per RNG", fig.height=4>>=
library(knitr)
rnd.data <- read.csv("../data/sac-2025-rndgen.csv")

library(ggplot2)
rnd.data$rndgen <- factor(rnd.data$rndgen)
ggplot(rnd.data, aes(x=rndgen, y=PKG, fill=rndgen)) +
  geom_boxplot(notch=T) +
  theme_minimal() +
  labs(title="PKG - Energy consumption of random number generators",
       x="Random number generator",
       y="Energy consumption (Joules)") +
  theme(legend.position="none")

differences <- pairwise.t.test(rnd.data$PKG, rnd.data$rndgen, p.adjust.method="none")

# print(differences)
library(dplyr)

rnd.data %>%
  group_by(rndgen) %>%
  summarise(mean=mean(PKG), sd=sd(PKG)) -> rnd.stats
ops <- 65535*2048

rnd.stats$ops.per.joule <- ops/ rnd.stats$mean
@

\section{Results}\label{sec:results}

\section{Conclusions}\label{sec:conclusions}
\begin{acks}
  Hidden for double-blind review
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{energy,GAs,ours,rng}

\end{document}
