\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{algorithm}
\usepackage{algorithmic}

\setcopyright{acmcopyright}

\acmDOI{xx.xxx/xxx_x}

\acmISBN{979-8-4007-0629-5/25/03}

%Conference
\acmConference[SAC'25]{ACM SAC Conference}{March 31 â€“April 4, 2025}{Sicily, Italy}
\acmYear{2025}
\copyrightyear{2025}


\acmArticle{4}
\acmPrice{15.00}

\begin{document}
\title{Minimizing the energy consumption of (pseudo) random number generators}
\subtitle{}

\renewcommand{\shorttitle}{Minimizing the energy consumption of (pseudo) random number generators}

\author{Ben Trovato}
\authornote{Boilerplate author names have been kept for double-blind review.}
\orcid{1234-5678-9012}
\affiliation{%
  \institution{Institute for Clarity in Documentation}
  \streetaddress{P.O. Box 1212}
  \city{Dublin}
  \state{Ohio}
  \country{USA}
  \postcode{43017-6221}
}
\email{trovato@corporation.com}

\renewcommand{\shortauthors}{B. Trovato}


\begin{abstract}
Pseudo random number generators are an essential part of every machine learning or metaheuristic algorithm. Even if every call will not, by itself, consume a large amount of energy, they are invoked so many times in any algorithm implementation that their consumption will add up to a significant amount, impacting overall consumption in several percentage points. In this poster we will examine what is the energy consumption, as well as the number of random number generated per joule, that can be achieved by different random number generators implemented in low-level languages. Our conclusion is that there can be a factor of two difference between the one that consumes the largest and the least amount of energy.
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}


\keywords{Green computing, software engineering, evolutionary algorithms, genetic algorithms, energy-aware algorithms, random number generators}


\maketitle

\section{Introduction}

Random number generators (RNGs) \cite{marsaglia2003random} are a class of algorithms that generate an unpredictable series of numbers with specific properties, or later converted to specific classes of values (like Boolean values or characters). They need a {\em seed} (which can be a single number or a vector of them) as input, and they will produce the {\em next} element in the cycle applying a series of operations to the seed and subsequent numbers generated from it. Those are generally {\em integer} operations; this is why, in general, RNGs are called {\em pseudo} RNGs: once the seed is known, the rest of the operations are deterministic. The complexity (and, inherently, the energy consumption) of these operations can go over a great range depending on the properties required from the RNG; so-called {\em cryptographycally secure} RNGs have the strictest requirements, and thus the lowest performance and highest energy consumption.

RNGs, however, are not used exclusively in cryptographic operations: any stochastic algorithm will need them, and will call them repeatedly in any kind of operations. Evolutionary algorithms, for instance, will need several calls to generate a point of mutation or crossover, as well as to generate randomly the initial population or any newly generated individual that is needed; that number of calls is bound to make an non-negligible impact in the overall operation that could be in the range of 10\%, constituting, besides, the gross of the time spent in operations such as mutation (which is essentially drawing a random number and then reassigning a number) or even reproduction (that needs random draws to decide pairings or which individuals participate in a tournament, depending on the selection methodology).

But, from the point of view of evolutionary algorithms, are RNG interchangeable? As a matter of fact, what a GA requires from a RNG is simply the ability to generate different numbers with a certain distribution; sometimes even low-cycle generators can be used \cite{zelinka2013evolutionary}; some papers have reported a low sensitivity of the GA to the RNG used \cite{cardenas2011sensitiveness}. This makes a matter of choice the selection of the RNG, and a matter of best practices to use the one that consumes the least amount of energy.

Consequently, in this paper we will try to examine energy consumption in several RNGs available, trying to select that spends the least amount of energy per call and is thus able to perform the maximum number of operations per Joule of energy consumed.

\section{Methodology}

As done in other papers \cite{zig1-anon,zig2-anon}, we will use the low-level language Zig  \cite{friesen2023designing}. {\sf zig} is an interesting target for evolutionary algorithms due to its low energy consumption, as well as high performance. Additionally, from the point of view of this paper it has got a wide range of RNGs available, from which we have selected 6, mainly chosen for their uniform interface that uses a single seed for initialization. These algorithms are Isaac64 \cite{jenkins1996isaac}, PCG \cite{o2014pcg}, RomuTrio \cite{overton2020romu}, SFC64 \cite{sfc64} and Xoshiro128/Xoroshiro256 \cite{blackman2021scrambled}. This is an interesting, as well as state-of-the-art, selection of RNGs.

We have created a program that instantiates one RNG of every model, and then proceeds to create 65535 Boolean {\em chromosomes}, every one of them with 2048 "bits". So it essentially calls the RNG $65535 \times 2048$ times, giving the benchmarking enough time to consume a small amount of energy.

<<sac.rnd.intro, echo=FALSE, message=FALSE, fig.cap="Boxplot of energy consumption per RNG", fig.height=4>>=
library(knitr)
rnd.data <- read.csv("../data/sac-2025-rndgen.csv")

library(ggplot2)
rnd.data$rndgen <- factor(rnd.data$rndgen)
ggplot(rnd.data, aes(x=rndgen, y=PKG, fill=rndgen)) +
  geom_boxplot(notch=T) +
  theme_minimal() +
  labs(title="PKG - Energy consumption of random number generators",
       x="Random number generator",
       y="Energy consumption (Joules)") +
  theme(legend.position="none")

differences <- pairwise.t.test(rnd.data$PKG, rnd.data$rndgen, p.adjust.method="none")

# print(differences)
library(dplyr)

rnd.data %>%
  group_by(rndgen) %>%
  summarise(mean=mean(PKG), sd=sd(PKG)) -> rnd.stats
ops <- 65535*2048

rnd.stats$ops.per.joule <- ops/ rnd.stats$mean
@

\section{Results}\label{sec:results}

\section{Conclusions}\label{sec:conclusions}
\begin{acks}
  Hidden for double-blind review
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{energy,GAs,ours,rng}

\end{document}
