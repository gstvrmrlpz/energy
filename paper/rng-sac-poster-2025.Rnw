\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{algorithm}
\usepackage{algorithmic}

\setcopyright{acmcopyright}

\acmDOI{xx.xxx/xxx_x}

\acmISBN{979-8-4007-0629-5/25/03}


\acmArticle{4}
\acmPrice{15.00}

\begin{document}
\title{Minimizing the energy consumption of (pseudo) random number generators in the low-level language {\sf zig}}
\subtitle{}

\renewcommand{\shorttitle}{Minimizing the energy consumption of (pseudo) random number generators for evolutionary algorithms}

\author{Juan J. Merelo}
\orcid{0000-0002-1385-9741}
\affiliation{%
    \institution{Department of Computer Engineering, Automatics and Robotics, Universidad de Granada/CITIC}
    \city{Granada}
    \country{Spain}
  }
\email{jmerelo@ugr.es}

\author{Gustavo Romero-LÃ³pez}
\affiliation{%
    \institution{Department of Computer Engineering, Automatics and Robotics, Universidad de Granada/CITIC}
    \city{Granada}
    \country{Spain}
  }
\email{gustavo@ugr.es}


\author{Mario Garc\'ia Valdez}
\affiliation{%
    \institution{Tecnol\'ogico Nacional de M\'exico}
    \city{Tijuana}
    \country{M\'exico}
}
\email{mario@tectijuana.edu.mx}

\renewcommand{\shortauthors}{Merelo et al.}


\begin{abstract}
Pseudo random number generators are an essential part of every machine learning or metaheuristic algorithm. Even if every call will not, by itself, consume a large amount of energy, they are invoked so many times in any algorithm implementation that their consumption will add up to a significant amount, impacting overall consumption in several percentage points. In this poster we will examine what the energy consumption is, as well as the number of random number generated per joule, that can be achieved by different random number generators implemented in low-level languages. Our conclusion is that there can be a factor of two difference between the one that consumes the largest and the least amount of energy.
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10011007.10011074.10011075.10011079.10011080</concept_id>
       <concept_desc>Software and its engineering~Software design techniques</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003809.10003716.10011136.10011797</concept_id>
       <concept_desc>Theory of computation~Optimization with randomized search heuristics</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10010061.10011795</concept_id>
       <concept_desc>Theory of computation~Random search heuristics</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003809.10003716.10011136.10011797.10011799</concept_id>
       <concept_desc>Theory of computation~Evolutionary algorithms</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10011007.10010940.10010941.10010949.10010957.10010964</concept_id>
       <concept_desc>Software and its engineering~Power management</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[300]{Software and its engineering~Software design techniques}
\ccsdesc[300]{Theory of computation~Optimization with randomized search heuristics}
\ccsdesc[500]{Theory of computation~Random search heuristics}
\ccsdesc[500]{Theory of computation~Evolutionary algorithms}
\ccsdesc[500]{Software and its engineering~Power management}

\keywords{Green computing, software engineering, evolutionary algorithms, genetic algorithms, energy-aware algorithms, random number generators}


\maketitle

\section{Introduction}

Random number generators (RNGs) \cite{marsaglia2003random} are a class of algorithms that generate an unpredictable series of numbers with specific properties, that can be later converted to specific classes of values (like Boolean values or characters).

They need a {\em seed} (which can be a single number or a vector of them) as input, and they will produce the {\em next} element in the cycle, applying a series of operations to the seed and subsequent numbers generated from it. Those are generally {\em integer} operations; this is why, in general, RNGs are called {\em pseudo} RNGs: once the seed is known, the rest of the operations are deterministic. The complexity (and, inherently, the energy consumption) of these operations can go over a great range depending on the properties required from the RNG; so-called {\em cryptographically secure} RNGs have the strictest requirements, and thus the lowest performance and highest energy consumption.

RNGs, however, are not used exclusively in cryptographic operations: any stochastic algorithm will need them and will call them repeatedly in any kind of operations. Evolutionary algorithms, for instance, will need several calls to generate a point of mutation or crossover, as well as to generate randomly the initial population or any newly generated individual that is needed; that number of calls is bound to make a non-negligible impact in the overall operation that could be in the range of 10\%, constituting, besides, the gross of the time spent in operations such as mutation (which is essentially drawing a random number and then reassigning a number) or even reproduction (that needs random draws to decide pairings or which individuals participate in a tournament, depending on the selection methodology).

But, from the point of view of evolutionary algorithms, are RNG interchangeable? As a matter of fact, what a GA requires from a RNG is simply the ability to generate different numbers with a certain distribution; sometimes even low-cycle generators can be used \cite{zelinka2013evolutionary}; some papers have reported a low sensitivity of the GA to the RNG used \cite{cardenas2011sensitiveness}. This makes a matter of choice the selection of the RNG, and a matter of best practices to use the one that consumes the least amount of energy.

Consequently, in this paper we will try to examine energy consumption in several RNGs available, trying to select one that spends the least amount of energy per call and is thus able to perform the maximum number of operations per Joule of energy consumed.

\section{Methodology}

As done in other papers \cite{zig1,zig2}, we will use the low-level language Zig  \cite{friesen2023designing}. {\sf zig} is an interesting target for evolutionary algorithms due to its low energy consumption, as well as high performance. Additionally, from the point of view of this paper, it has a wide range of RNGs available, from which we have selected 6, mainly chosen for their uniform interface that uses a single seed for initialization. These algorithms are Isaac64 \cite{jenkins1996isaac}, PCG \cite{o2014pcg}, RomuTrio \cite{overton2020romu}, SFC64 \cite{sfc64} and Xoshiro128/Xoroshiro256 \cite{blackman2021scrambled}. This is an interesting, as well as state-of-the-art, selection of RNGs.

We have created a program that instantiates one RNG of every model, and then proceeds to create 65535 Boolean {\em chromosomes}, every one of them with 2048 "bits". So, it essentially calls the RNG $65535 \times 2048$ times, giving the benchmarking enough time to consume a small amount of energy. Every program is run 30 times through the {\sf pinpoint} energy profiler \cite{pinpoint}. The time spent for the 30 runs is then averaged, and a {\sf sleep} command with the average is run. The energy measured for that command (which would reflect the background energy consumption while running the program) is then subtracted from the individual measures before performing any additional processing\footnote{The script is free software and available from the repository of this paper, along with experimental data with a free license}.

<<sac.rnd.intro, echo=FALSE, message=FALSE, fig.cap="Boxplot of energy consumption per RNG", fig.height=4>>=
library(knitr)
rnd.data <- read.csv("../data/sac-2025-rndgen.csv")

library(ggplot2)
rnd.data$rndgen <- factor(rnd.data$rndgen)
ggplot(rnd.data, aes(x=rndgen, y=PKG, fill=rndgen)) +
  geom_boxplot(notch=T) +
  theme_minimal() +
  labs(title="PKG - Energy consumption of random number generators",
       x="Random number generator",
       y="Energy consumption (Joules)") +
  theme(legend.position="none")
@

\section{Results}\label{sec:results}

Results are shown in Figure \ref{fig:sac.rnd.intro}, which represents a boxplot for the energy consumption of every RNG mentioned above. The consumption of all RNGs is in the same range (of around 10 Joules), but there are differences from the one that consumes the most (Isaac64) to the one with the least carbon footprint, called RomuTrio.

<<sac.rnd.stats, echo=FALSE, message=FALSE>>=
differences <- pairwise.t.test(rnd.data$PKG, rnd.data$rndgen, p.adjust.method="none")

# print(differences)
library(dplyr)

rnd.data %>%
  group_by(rndgen) %>%
  summarise(mean=mean(PKG), sd=sd(PKG)) -> rnd.stats
ops <- 65535*2048

rnd.stats$ops.per.joule <- ops/ rnd.stats$mean
library(kableExtra)

rnd.stats %>% arrange(mean) %>% kable(digits=2, col.names=c("RNG","Mean consumption (J)", "SD", "Ops/Joule"), caption="Energy consumption and operations per Joule")
@

Differences are significant via pairwise T-test, except in the case of Xoshiro, Xoroshiro, and PCG, as can be appreciated in the image. These are mid-performance RNGs, so that does not hide the fact that there is a clear winner, consuming the least energy, and a loser. This is highlighted in Table \ref{tab:sac.rnd.stats}, which shows the different RNGs ranked in order of operations per Joule. As it can be seen, using the best RNG can spend roughly half the amount of energy the worst one does, and thus obtain 17 million operations per Joule as opposed to 8. romuTrio is \Sexpr{round((rnd.stats[3,]$ops.per.joule/rnd.stats[2,]$ops.per.joule - 1)*100,2)}\% faster than its follower, PCG, too, so there is a clear advantage in choosing it.

\section{Conclusions}\label{sec:conclusions}

<<sac.rnd.conclusions, echo=FALSE, message=FALSE>>=
rnd.w.secs.data <- read.csv("../data/sac-2024-rndgen-secs.csv")
rnd.w.secs.data %>%
  group_by(size) %>%
  summarise(mean=mean(s), sd=sd(s)) -> rnd.w.secs.stats
@

In this paper, we set out to choose the most energy-efficient RNG for use in metaheuristics and other applications that have low sensitivity to the quality of the RNG used. We have chosen 6 RNGs implemented in the language {\sf zig} and followed a methodology that allows us to compute the energy spent in every function call generating a random number. The methodology offers us a good estimation of the real value, although it is by no means a precise value; however, by eliminating the system overhead via a simple operation, we think the results are solid enough to base a decision on them.

It should be noted that in this paper, we are not concerned with the speed. As a matter of fact, Romutrio is \Sexpr{round((rnd.w.secs.stats[3,]$mean/rnd.w.secs.stats[2,]$mean - 1)*100,2)}\% slower than the second that consumes the least. This points to the fact that RomuTrio is drawing less power (power being energy/time) than the competitor, meaning that possibly the operations used employ specific parts of the CPU that draw less power, or taking into account the nature of modern CPU power management, that it employs {\em less} parts of them, enabling power management to simply turn them off.

As conclusion, besides the proven fact that RomuTrio is the RNG that offers the best energy saving, we should add that using a methodology that allows us to analyze functions that are used repeatedly through algorithm implementation, besides functions that are specific to the algorithm (like, in the case of evolutionary algorithm, mutation and crossover) will give us more leverage to save energy, although in numerical terms it cannot really be called dramatic.

As future, or rather parallel, lines of work, we will use the information here to inform all future analyses of energy savings in evolutionary algorithms, analyzing first whatever common, low-level functions are used to come up with the best implementarion, before going up to analyze higher-level, algorithm-specific functions.

\begin{acks}
This work is supported by the Ministerio espa\~{n}ol de Econom\'{\i}a y
Competitividad (Spanish Ministry of Competitivity and Economy) under project
PID2020-115570GB-C22 (DemocratAI::UGR), as well as PID2023-147409NB-C22.
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{energy,GAs,ours,rng}

\end{document}
