%%
%% Copyright 2007-2024 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.3 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%%
%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01
%% $Id: elsarticle-template-num.tex 249 2024-04-06 10:51:24Z rishi $
%%
\documentclass[preprint,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsmath package provides various useful equation environments.
\usepackage{amsmath}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

\usepackage{hyperref}
\usepackage{xcolor} % highlight
\usepackage{soul}   % highlight

\journal{Swarm and Evolutionary Computation}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \affiliation for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%% \fntext[label3]{}

\title{Minimizing energy consumption in evolutionary algorithms implementations in C++}

\author[icar]{Gustavo Romero-López}
\author[icar,citic]{Juan J. Merelo-Guervós} %% Author name

%% Author affiliation
\affiliation[icar]{organization={Department of Computer Engineering, Automatics and Robotics},%Department and Organization
            city={Granada},
            postcode={18071},
            country={Spain}}
%% Abstract
\begin{abstract}
%% Text of abstract
Abstract text.
\end{abstract}

%%Graphical abstract
\begin{graphicalabstract}
%\includegraphics{grabs}
\end{graphicalabstract}

%%Research highlights
\begin{highlights}
\item Research highlight 1
\item Research highlight 2
\end{highlights}

%% Keywords
\begin{keyword}
%% keywords here, in the form: keyword \sep keyword

%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

%% Add \usepackage{lineno} before \begin{document} and uncomment
%% following line to enable line numbers
%% \linenumbers

%% main text
%%

%% Use \section commands to start a section
\section{Introduction}
\label{intro}

In an evolutionary algorithm context, beyond the search for the best algorithm and performance, it is interesting to try and optimize the energy consumption of known algorithms, maximizing the number of operations performed by unit of energy. This happens in a context that tries to make computing, and scientific computing in general, more sustainable, and has led to efforts in examining the energy consumption of applications and algorithm implementations from different angles, focusing for instance on the language used \cite{PEREIRA2021102609} or restricting the workload to a class of problems for instance, those generically called Artificial Intelligence \cite{verdecchia2023systematic,hidalgo2023sustainable} or even more to the point, to evolutionary algorithms \cite{icsoft,zig1}

There are several challenges when performing this optimization. While the tooling for optimizing performance are well established, and it is possible to know how many low-level CPU calls every high-level function performs, and how much every one of these take, making possible a very fine-grained optimization of performance, that is not the case for the consumption of energy. Only system-wide measurements can be made, \hl{and only of instantaneous consumption while an application is running}\footnote{consumo total, no?}. This is why the first step in optimizing algorithm implementations is to identify which functions, by number of calls or simply time needed, are critical. While the number of calls will obviously be the same either optimizing for performance or energy consumption, the assumption here is that time spent in a function will roughly correspond to energy consumed. And that is, in general, true, but it could happen that two functions with a similar time performance would invert the energy consumption profile, as proof in \cite{PEREIRA2021102609}. At any rate, and as indicated, this is impossible to know in advance, so the best practice in this case is to model the workload of an algorithm, choosing all functions that determine the performance as extracted from a profiling tool \cite{7155416}.

The best practice used so far is to take into account only \hl{integer-based}\footnote{por qué enteros?} operations: crossover and mutation (which are called many times in an evolutionary algorithm) and an integer based fitness function. While \hl{MaxOnes}\footnote{no es onemax más usual?} \cite{back1993optimal} is popular and used extensively in benchmarking new operators and algorithm versions, computing requires a relatively low amount of energy, so it can be considered alongside mutation and crossover \cite{zig1,zig2}; other more complicated fitness functions can also be taken into account: Hierarchical If-and-Only-If problem (HIFF) \cite{watson1998modeling} is one of them, with the added advantage of being a recursive function, an operation that can involve heap and stack memory allocations and that can reveal energy inefficiencies in the language, it is used in \cite{zig1,zig2}.

Establishing these profiles is not the main goal of this paper, however, although we need to admit in advance that optimizing energy consumed by these specific functions will have an impact on the overall sustainability of the algorithm implementation. In many cases, the language used in an implementation will be also fixed in advance. Several languages are, and have been, popular for implementing evolutionary algorithms: Java \cite{scott2019ecj,medvet2022jgea}, C and C++ \cite{jakobovic2024ecf,dreo2021paradiseo,tarkowski2023quile}, and lately Python \cite{de2012deap,coletti2020library,tonda2020inspyred,sipper2023ec,toklu2023evotorch}. Certainly the latter is more popular in terms of number of libraries, but it has been repeatedly proved in general-purpose workloads that the energy consumption of Python can be up to two orders of magnitude higher than that of C++ \cite{10.1145/3139367.3139418}. This is due to the fact that C++ is a compiled language, as well as to specific features that, when used properly, can further reduce energy consumption \cite{porkolab2022save}. The fact that C++ is chosen for implementing an evolutionary algorithm, by itself, is already an energy-saving choice. But in this paper we will delve even further energy-saving options that can reduce energy consumption even further.

C++ is a compiled language \cite{godbolt2020optimizations}. Compiling consists in examining statically the code and performing a series on transformation on the parsed version so that the machine code produced is as efficient as possible. C++ compilers are among the more complex ones. Their work is the transformation of source code into an executable. The whole process involves many steps that can be executed in a single pass or a multi-pass way. This affects the speed and memory consumption of the process, but the final result can be exactly the same except for some kinds of optimizations. The classic process follows approximately these phases \cite{alfred2007compilers}:
\begin{enumerate}
    \item Analysis: Is the source code correct?
    \begin{enumerate}
    \item Lexical analysis: the text is converted into a collection of tokens belonging to certain categories.
    \item Syntactic analysis: analyze the symbols to check if they conform to the rules of the formal grammar of the language.
    \item Semantic analysis: gather semantic information about the source code to be able to check for many errors, such as type checking.
    \end{enumerate}
\item Synthesis: only after the analysis phase finds that the program is free of errors, the object code is generated. It can be directly in assembly code or any form of intermediate representation.
\item Optimization: improve the quality of the intermediate representation by means of any desired quantity such as execution time, memory/storage use, or power consumption; generally the two former are preferred over the latter, or even the only ones considered.
\item Code generation: target machine code for an operating system is finally generated.
\end{enumerate}

The two last phases are the most important from the point of view of optimization, including energy optimization. This is why once those bottlenecks are found, we are faced with a myriad of possibilities, even if we restrict, like we do in our paper, to a single programming language. Compiled languages like this one have different options that affect performance in a more or less predictable way, and energy consumption in a way that is not known in advance. Let's examine them:\begin{itemize}
\item The first level implies choosing a compiler: Most compiled languages have different standard-compliant compilers, designed and produced by different open source or commercial organizations. In the case of C++, there are at least two major ones: clang++, from LLVM \cite{lattner2008llvm}, and g++ \cite{stallman2002gnu}, from GNU. That without even taking into account different language standards and different compiler versions.
\item The second level is the different options that you can use when generating the executable. \begin{itemize}
    \item Most compilers have options regarding the architecture and machine instruction set that should be targeted. Programs can be compiled for a generic architecture, e.g. {\tt -march=i686}, or include instructions set that are specific to a brand or generation, e.g. {\tt -mtune=znver5}.
    \item The optimization level is also a compiler flag, that usually targets performance. Checking which optimization level, or which combination of optimization high-level flags is the best for energy consumption is not a priori known, and needs to be measured. This is controversial flag as for many years, the maximun optimization level {\tt -O3}, has been considered buggy and not completly reliable, but not anymore.
    \item Some compiler use an intermediate representation, mainly with the object of allowing static analysis as well as cross-compilation, but this representation can have an impact optimization as well as energy consumption. % no es posible probarlas - tampoco los algoritmos, pero habrá que poner todos los temas posibles.
    \item Finally, compilers allow user selection of the language standard that is being followed. This might affect, besides the language constructs that are allowed, how code is generated. % no afecta significativamente JJ - pues se pone en la exploración inicial
\end{itemize}
\item The next level is the algorithm level: there are always different ways to implement the code, which can have different complexity, but also different energy consumption depending on how CPU and memory are used and how the code for the specific implementation is generated. Although this can certainly be examined for a different problem or workload, in evolutionary algorithms the amount of improvements we can obtain is very limited.
\item At the language level we can use different data structures to implement the problem domain objects; in general, an algorithm is not going to specify the specific data structure that needs to be used; choosing one or the other will impact energy consumption if only for the different memory layout and occupation that every one has. The classic speed vs size trade off that may arise from every problem, e.g. using {\tt std::vector<bool>} vs {\tt std::vector<char>} to implement a vector of boolean values; there might be other trade offs involved related to the complexity of accessing data packed in structures through references to individual bits.
\end{itemize}

In this paper we will try to find a combination of parameters and engineering choices that minimize energy consumption in a generic evolutionary algorithm by systematically researching the amount of energy consumed by common EA operators, and an integer-based heavy-weight function, the HIFF problem. And we will do so by answering the following research questions:\begin{itemize}
\item RQ1 Are there combinations, parameter values or choices that can be discarded by baseline measures because they are either neutral from the point of view of energy spent or significantly slower than others?
\item RQ2 What kind of decisions have the biggest impact on energy consumption?
\item RQ3 Are rankings of energy consumption consistent across different architectures?
\item RQ4 How does the power consumption of C++ evolve as its versions and standards advance? % standards probably very little, versions probably a lot
\end{itemize}

\section{Methodology}

There is no fixed methodology for measuring energy consumption across a number of different machines with possibly different operating systems and hardware architectures. In \cite{jay2023experimental} Jay el al. delves into energy consumption, its measurement and the software tools needed to gather information about. The most widely used tool for its convenience is the Running Average Power Limit (RAPL) \cite{david2010rapl} interface through a wide range of tools like {\sf perf} \cite{de2010new}.

This is the approach followed in previous work \cite{zig1,zig2}, although by using the {\sf pinpoint} \cite{9307947} software as a {\sf perf} alternative we can also measure energy in MacOS. Since in this paper we are focused on specific languages, in principle independently of the operating system, {\sf perf} can perfectly cover what we are looking for. Using this tool, our methodology will follow the steps shown below:
\begin{itemize}
\item Decide which functions were the target for profiling, since energy profilers are unable to measure energy consumption at the function, or function call, level, thus needing to create executables where single functions are executed.
\item From those energy profiles, a baseline needs to be established. This baseline should include any energy expenses of the system, and, if possible, energy spent in data initialization and preparation. This baseline measurements can include discarding parametrizations or options that are either statistically indistinguishable from others or simply spending too much energy to be considered.
\item Finally, an experimental setup where different, relevant configurations and parametrizations are cross-tested so that those with the lowest energy performance can be selected and explained.
\end{itemize}

The experiments were run on a PC with AMD Ryzen 7 3700X processor, 32GiB of DDR4 memory and 500GiB KINGSTON SA2000M8500G NVMe drive. The operating system is Fedora Linux 40 Workstation Edition with kernel version 6.9.10-200.fc40.x86\_64. The compilers used are clang++ version 18.1.6 and g++ version 14.1.1.

<<energy.setup, echo=F,message=F,warning=F>>=
library(dplyr)
library(ggplot2)
library(kableExtra)

pccito.raw <- read.csv("../data/v3/pccito-20240726-215614.csv",sep=";")
pccito.init <- pccito.raw[pccito.raw$work=="i",]
pccito.init$work <- NULL

pccito.init %>% group_by(compiler,opt,program,length,std) %>% summarise(mean.energy=mean(energy),sd.energy=sd(energy),mean.time = mean(time), sd.time = sd(time)) -> pccito.summary

wilcox.packed <- data.frame(length=numeric(),compiler=character(),opt=character(),std=character(),p.value=numeric(),significant=logical(),bitset.avg=numeric(),bvector.avg=numeric(),bitset.better=logical())
wilcox.unpacked <- data.frame(length=numeric(),compiler=character(),opt=character(),std=character(),p.value=numeric(),significant=logical(),cvector.avg=numeric(),string.avg=numeric(),cvector.better=logical())
for (l in c(512,1024,2048)) {
  for (compiler in c("clang++","g++")) {
    for (opt in c("-O2","-O3")) {
      for ( std in c("-std=c++17","-std=c++20","-std=c++23")) {
        wt <- wilcox.test(
          pccito.init[ pccito.init$program=="bitset" & pccito.init$length == l & pccito.init$compiler == compiler & pccito.init$opt == opt & pccito.init$std == std,]$energy,
          pccito.init[ pccito.init$program=="bvector" & pccito.init$length == l & pccito.init$compiler == compiler & pccito.init$opt == opt & pccito.init$std == std,]$energy)
        wp.df <- data.frame(
                                length=l,compiler=compiler,opt=opt,std=std,p.value=wt$p.value,significant=wt$p.value < 0.05, bitset.avg = pccito.summary[ pccito.summary$program=="bitset" & pccito.summary$length == l & pccito.summary$compiler == compiler & pccito.summary$opt == opt & pccito.summary$std == std,]$mean.energy, bvector.avg = pccito.summary[ pccito.summary$program=="bvector" & pccito.summary$length == l & pccito.summary$compiler == compiler & pccito.summary$opt == opt & pccito.summary$std == std,]$mean.energy
                               )
        wp.df$bitset.better <- wp.df$bitset.avg < wp.df$bvector.avg

        wilcox.packed <- rbind(wilcox.packed, wp.df)

        wt.u <- wilcox.test(
          pccito.init[ pccito.init$program=="cvector" & pccito.init$length == l & pccito.init$compiler == compiler & pccito.init$opt == opt & pccito.init$std == std,]$energy,
          pccito.init[ pccito.init$program=="string" & pccito.init$length == l & pccito.init$compiler == compiler & pccito.init$opt == opt & pccito.init$std == std,]$energy,paired=FALSE)
        wu.df <- data.frame(length=l,compiler=compiler,opt=opt,std=std,p.value=wt.u$p.value,significant=wt.u$p.value < 0.05, cvector.avg = pccito.summary[ pccito.summary$program=="cvector" & pccito.summary$length == l & pccito.summary$compiler == compiler & pccito.summary$opt == opt & pccito.summary$std == std,]$mean.energy, string.avg = pccito.summary[ pccito.summary$program=="string" & pccito.summary$length == l & pccito.summary$compiler == compiler & pccito.summary$opt == opt & pccito.summary$std == std,]$mean.energy )
        wu.df$cvector.better <- wu.df$cvector.avg < wu.df$string.avg
        wilcox.unpacked <- rbind(wilcox.unpacked,wu.df)
      }
    }
  }
}

summary.noO2 <- pccito.summary[ pccito.summary$opt=="-O2",]
summary.noO2$opt <- NULL
summary.noO2  %>% arrange(length,compiler,program) %>% kable(caption="Energy consumption by compiler and data structure, optimization level = O2")  %>% kable_styling(font_size = 5)

@



<<energy.setup.2, echo=F,message=F,warning=F>>=
summary.noO3 <- pccito.summary[ pccito.summary$opt=="-O3",]
summary.noO3$opt <- NULL
summary.noO3 %>% arrange(length,compiler,program)  %>% kable(caption="Energy consumption by compiler and data structure, optimization level = O3") %>% kable_styling(font_size = 5)

pccito.init$length <- as.factor(pccito.init$length)
# ggplot(pccito.init[ pccito.init$program == "bitset",],aes(x=length,y=energy,color=X.compiler, shape=opt)) + geom_point(alpha=0.4) + geom_jitter(width=0.2) + theme_minimal() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + labs(title="Energy consumption by compiler and optimization level",x="time",y="Energy consumption (Joules)") + scale_fill_brewer(palette="Set1")

pccito.energy.lm <- lm(energy ~  program + opt + compiler + length + std, data=pccito.init)

data.512 <- pccito.summary[ pccito.summary$length == 512,]
min.energy.512 <- data.512[which.min(data.512$mean.energy),]

data.1024 <- pccito.summary[ pccito.summary$length == 1024,]
min.energy.1024 <- data.1024[which.min(data.1024$mean.energy),]

data.2048 <- pccito.summary[ pccito.summary$length == 2048,]
min.energy.2048 <- data.2048[which.min(data.2048$mean.energy),]

@


As we have done in other papers, we will use the initialization of the set of chromosomes with different parametrizations to establish the baseline, but at the same time to eliminate, from the start, any configuration that we can confidently establish as not sufficiently energy-efficient. In order to do that we have run a set of 15 tests with every parametrization using two compilers (g++ and clang++), two possible optimization levels of the compiler (-O2 and -O3), as well as the usual three chromosome lengths: 512, 1024 and 2048. We have also tested 4 different data structures to represent the chromosome:\begin{itemize}
\item \texttt{bitset} uses the C++ dynamic bitset data structure. % maybe add more about this one.
\item \texttt{bvector} uses the C++ vector data structure from the standard template library, instantiated with the \texttt{bool} type.
\item \texttt{cvector} uses the C++ vector data structure from the standard template library, instantiated with characters.
\item \texttt{string} uses C++ strings, with chars '1' and '0' representing the integer values {\tt 1} and {\tt 0}.
\end{itemize}

The main difference between the first two data structures and the second ones is the fact that the former are {\em packed}, that is, in order to save memory, bits are packed to a byte; the latter are not. This will imply a certain effort to "unpack" them in order to use them, which might have an impact in the energy consumption. This is effectively what we can observe in Table \ref{tab:energy.setup}, and \ref{tab:energy.setup.2}, where we group these types of data structures (run as different programs) in a single column, and we can observe than, in general (with a few exceptions), for every compiler and optimization level, "packed" structures consume more energy than non-packed ones.

We will test the energy behavior of several different parameters, besides those above\begin{itemize}
\item C++, as any other language, periodically approves standards that include, in some cases, new instructions that might improve the energy profile of the applications. We will test three levels, for the C++17, C++20 and C++23 standards.
\item As indicated above, there are different open source compilers that implement the C++ standard. Most are based either in the GNU compiler g++ or the LLVM compiler clang++. Both will be tested on our workload.
\item Any compiler offers different optimization levels, indicated with the $O$ flag, with the $-O2$ and $-O3$ being the most significant\footnote{$-O1$ will usually imply no optimization, and in most compilers, $-O4$ will be equivalent to the previous value.}.
\end{itemize}

These will be tested for 3 different chromosome lengths: 512, 1024 and 2048. Except for the first one, these are lengths which are seldom seen in actual optimization problems outside benchmarks; however, we have used them so that there is a significant amount of consumption to make meaningful comparisons. Experiments have been repeated 15 tims for statistical significance, and every one corresponds to the generation of 40000 chromosomes.

The initial results are laid out in Tables \ref{tab:energy.setup} and \ref{tab:energy.setup.2}; the former shows averages and standard deviations for $-O2$, while the latter does the same for $-O3$. As indicated, these measurements include chromosome initialization as well as machine overhead; the double intention of these measurements is to answer research question 1 regarding initial parametrizations to be discarded as well as subtract it later on for the measurement of the functions that constitute the workload whose energy consumption is to be minimized. These tables allow an initial appraisal of what is to be expected with the different parametrizations. In general, there is a tight correlation between energy consumed and time needed to run the workload; both grow with the chromosome size, and, against intuition, seem to be somewhat higher for the $-O3$ optimization level in Table \ref{tab:energy.setup.2}. However, this will need a more rigorous analysis.

We can, for instance, observe some differences and similarities among the energy consumed by the data structures of every type. As a matter of fact, all other factors being equal, there is a significant difference between energy spent by \texttt{cvector} and \texttt{string} only in \Sexpr{length(wilcox.unpacked[ wilcox.unpacked$significant==T,]$significant)/length(wilcox.unpacked$significant)*100}\% of the cases; and out of those, in \Sexpr{100*length(wilcox.unpacked[ wilcox.unpacked$significant==T & wilcox.unpacked$cvector.better==T,]$significant)/length(wilcox.unpacked[ wilcox.unpacked$significant==T,]$significant)}\% \texttt{cvector} is better than \texttt{string}. So we will from now on drop the use of \texttt{string} as a data structure to represent the chromosomes.

% \hl{There are some exceptions: when -O2 is used, g++ consumes less energy for packed structures for every length of the chromosome. We can apply a linear model for prediction of consumption depending on the rest of the factors.}\footnote{tengo que estudiar las gráficas a fondo para poder asegurar esto...}
% No pasa nada si hay excepciones; en todo caso creo que vamos a descartar sólo un tipo de estructuras, y quizás el clang++. La optimización la dejaremos como está.

<<energy.std, echo=F,message=F,warning=F>>=
pccito.std.raw <- read.csv("../data/v3/pccito-20240726-215614.csv",sep=";")

pccito.std.raw %>% group_by(compiler,opt,program,work,length,std) %>% summarise(mean.energy=mean(energy),sd.energy=sd(energy),mean.time = mean(time), sd.time = sd(time)) -> pccito.std.summary

pccito.std.noinit <- pccito.std.raw[ pccito.std.raw$work != "i",]

for (i in rownames(pccito.std.noinit) ) {
  row <- pccito.std.noinit[i,]
  row.summary <- pccito.std.summary[ pccito.std.summary$work == "i" & pccito.std.summary$compiler == row$compiler & pccito.std.summary$opt == row$opt & pccito.std.summary$program == row$program & pccito.std.summary$length == row$length & pccito.std.summary$std == row$std,]

  pccito.std.noinit[i,"diff.energy"] <- row$energy - row.summary$mean.energy
  pccito.std.noinit[i,"diff.time"] <- row$time - row.summary$mean.time

}

pccito.std.noinit %>% group_by(compiler,opt,program,work,length,std) %>% summarise(mean.diff.energy=mean(diff.energy),sd.diff.energy=sd(diff.energy),mean.diff.time = mean(diff.time), sd.diff.time = sd(diff.time)) -> pccito.std.noinit.summary

@

\section{Results}
\label{sec:res}

\section{Conclusions}
\label{sec:con}

\section*{Acknowledgements}

This work is supported by the Ministerio espa\~{n}ol de Econom\'{\i}a y
Competitividad (Spanish Ministry of Competitivity and Economy) under project
PID2020-115570GB-C22 (DemocratAI::UGR), as well as PID2023-147409NB-C22.

\bibliographystyle{elsarticle-num}
\bibliography{cplusplus,cplusplus-energy,energy,GAs,libraries,ours}

%% else use the following coding to input the bibitems directly in the
%% TeX file.

%% Refer following link for more details about bibliography and citations.
%% https://en.wikibooks.org/wiki/LaTeX/Bibliography_Management


\end{document}

\endinput
%%
%% End of file `elsarticle-template-num.tex'.
